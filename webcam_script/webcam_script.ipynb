{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webcam App Development\n",
    "This notebook contains the various steps in developing the webcam application as well as the ideation behind the script. The actual script is located here.\n",
    "\n",
    "## Necessary installations\n",
    "The user needs:\n",
    "\n",
    "- cmake: use brew install cmake from the command line after installing homebrew\n",
    "- dlib: can be installed with pip install dlib after cmake is built\n",
    "- face_recognition: after all of the above are installed, pip install face_recognition\n",
    "- OpenCV: pip install opencv-python\n",
    "- Playsound: First: pip instal pip install playsound\n",
    "\n",
    "If using Windows:\n",
    "\n",
    "Follow the above instructions except use Anaconda to install dlib in the step after installing cmake: conda install -c conda-forge dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 ## for the webcam and computer vision\n",
    "import numpy as np \n",
    "from playsound import playsound ## alert sound\n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition ## face recognition\n",
    "from tensorflow import keras ## for loading in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make sure to specify the filepath to the model if needed\n",
    "eye_model = keras.models.load_model('best_model_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye Cropper function\n",
    "We need this function to optimize the image for the model. When a frame from the webcam is taken, it will be sent to this function and outputted in a format the model will be able to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_cropper(frame):\n",
    "\n",
    "    # create a variable for the facial feature coordinates\n",
    "\n",
    "    facial_features_list = face_recognition.face_landmarks(frame)\n",
    "\n",
    "\n",
    "    # create a placeholder list for the eye coordinates\n",
    "    # and append coordinates for eyes to list unless eyes\n",
    "    # weren't found by facial recognition\n",
    "\n",
    "    try:\n",
    "        eye = facial_features_list[0]['left_eye']\n",
    "    except:\n",
    "        try:\n",
    "            eye = facial_features_list[0]['right_eye']\n",
    "        except:\n",
    "            return\n",
    "\n",
    "\n",
    "    # establish the max x and y coordinates of the eye\n",
    "\n",
    "    x_max = max([coordinate[0] for coordinate in eye])\n",
    "    x_min = min([coordinate[0] for coordinate in eye])\n",
    "    y_max = max([coordinate[1] for coordinate in eye])\n",
    "    y_min = min([coordinate[1] for coordinate in eye])\n",
    "\n",
    "\n",
    "    # establish the range of x and y coordinates\n",
    "\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "\n",
    "\n",
    "      # in order to make sure the full eye is captured,\n",
    "      # calculate the coordinates of a square that has a\n",
    "      # 50% cushion added to the axis with a larger range and\n",
    "      # then match the smaller range to the cushioned larger range\n",
    "\n",
    "    if x_range > y_range:\n",
    "        right = round(.5*x_range) + x_max\n",
    "        left = x_min - round(.5*x_range)\n",
    "        bottom = round((((right-left) - y_range))/2) + y_max\n",
    "        top = y_min - round((((right-left) - y_range))/2)\n",
    "    else:\n",
    "        bottom = round(.5*y_range) + y_max\n",
    "        top = y_min - round(.5*y_range)\n",
    "        right = round((((bottom-top) - x_range))/2) + x_max\n",
    "        left = x_min - round((((bottom-top) - x_range))/2)\n",
    "\n",
    "\n",
    "    # crop the image according to the coordinates determined above\n",
    "\n",
    "    cropped = frame[top:(bottom + 1), left:(right + 1)]\n",
    "\n",
    "    # resize the image\n",
    "\n",
    "    cropped = cv2.resize(cropped, (80,80))\n",
    "    image_for_prediction = cropped.reshape(-1, 80, 80, 3)\n",
    "\n",
    "\n",
    "    return image_for_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webcam Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Webcam is accessed\n",
    "- Implement the eye_cropper function to optimize each frame for the model\n",
    "- Run the cropped frame of the eye through the model to predict whether it is closed or not\n",
    "- If the prediction is closed for more than 2 frames, then alert the user with a sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate webcam\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "print(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise IOError('Cannot open webcam')\n",
    "counter = 0\n",
    "\n",
    "# create a while loop that runs while webcam is in use\n",
    "\n",
    "while True:\n",
    "\n",
    "    #creating a while loop that runs when webcam is in use\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # use only every other frame to manage speed and memory usage\n",
    "\n",
    "    frame_count = 0\n",
    "    if frame_count == 0:\n",
    "        frame_count += 1\n",
    "        pass\n",
    "    else:\n",
    "        count = 0\n",
    "        continue\n",
    "\n",
    "    # function called on the frame\n",
    "\n",
    "    image_for_prediction = eye_cropper(frame)\n",
    "    try:\n",
    "        image_for_prediction = image_for_prediction/255.0\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # get prediction from model\n",
    "\n",
    "    prediction = eye_model.predict(image_for_prediction)\n",
    "\n",
    "    # Based on prediction, display either \"Open Eyes\" or \"Closed Eyes\"\n",
    "\n",
    "    if prediction < 0.5:\n",
    "        counter = 0\n",
    "        status = 'Open'\n",
    "        cv2.putText(frame, status, (round(w/2)-80,70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 2, cv2.LINE_4)\n",
    "\n",
    "    else:\n",
    "        counter = counter + 1\n",
    "        status = 'Closed'\n",
    "        cv2.putText(frame, status, (round(w/2)-104,70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255), 2, cv2.LINE_4)\n",
    "       \n",
    "        # if the counter is greater than 3, play and show alert that user is asleep\n",
    "\n",
    "        if counter > 2:\n",
    "            cv2.putText(frame, 'DRIVER SLEEPING', (round(w/2)-136,round(h) - 146), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2, cv2.LINE_4)\n",
    "            cv2.imshow('Drowsiness Detection', frame)\n",
    "            k = cv2.waitKey(1)\n",
    "            playsound('rooster.mov')\n",
    "            counter = 1\n",
    "            continue\n",
    "    cv2.imshow('Drowsiness Detection', frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Read Me](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bba57c57bd0d3f5a034a7deea61d6dd51f420f3741796b2182944766e622788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
